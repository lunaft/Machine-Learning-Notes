{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm') #es_core_news_sm este modelo hay que instalarlo para trabajar en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.es.Spanish"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"\"\" En un pueblo de la Mancha,\n",
    "de cuyo nombre no quiero acordarme,\n",
    "vivió no hace mucho tiempo un hidalgo.\n",
    "Nuestro hidalgo se llamaba Alonso Quijano.\n",
    "Tenía muchos años y era muy delgado.\n",
    "Don Alonso poseía un caballo flaco,\n",
    "unas tierras y una casa muy grande.\n",
    "El hidalgo vivía con su joven sobrina\n",
    "y una criada. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " En un pueblo de la Mancha,\n",
      "de cuyo nombre no quiero acordarme,\n",
      "vivió no hace mucho tiempo un hidalgo.\n",
      "Nuestro hidalgo se llamaba Alonso Quijano.\n",
      "Tenía muchos años y era muy delgado.\n",
      "Don Alonso poseía un caballo flaco,\n",
      "unas tierras y una casa muy grande.\n",
      "El hidalgo vivía con su joven sobrina\n",
      "y una criada. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documento = nlp(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "En\n",
      "un\n",
      "pueblo\n",
      "de\n",
      "la\n",
      "Mancha\n",
      ",\n",
      "\n",
      "\n",
      "de\n",
      "cuyo\n",
      "nombre\n",
      "no\n",
      "quiero\n",
      "acordarme\n",
      ",\n",
      "\n",
      "\n",
      "vivió\n",
      "no\n",
      "hace\n",
      "mucho\n",
      "tiempo\n",
      "un\n",
      "hidalgo\n",
      ".\n",
      "\n",
      "\n",
      "Nuestro\n",
      "hidalgo\n",
      "se\n",
      "llamaba\n",
      "Alonso\n",
      "Quijano\n",
      ".\n",
      "\n",
      "\n",
      "Tenía\n",
      "muchos\n",
      "años\n",
      "y\n",
      "era\n",
      "muy\n",
      "delgado\n",
      ".\n",
      "\n",
      "\n",
      "Don\n",
      "Alonso\n",
      "poseía\n",
      "un\n",
      "caballo\n",
      "flaco\n",
      ",\n",
      "\n",
      "\n",
      "unas\n",
      "tierras\n",
      "y\n",
      "una\n",
      "casa\n",
      "muy\n",
      "grande\n",
      ".\n",
      "\n",
      "\n",
      "El\n",
      "hidalgo\n",
      "vivía\n",
      "con\n",
      "su\n",
      "joven\n",
      "sobrina\n",
      "\n",
      "\n",
      "y\n",
      "una\n",
      "criada\n",
      ".\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in documento:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SPACE\n",
      "En ADP\n",
      "un DET\n",
      "pueblo NOUN\n",
      "de ADP\n",
      "la DET\n",
      "Mancha PROPN\n",
      ", PUNCT\n",
      "\n",
      " SPACE\n",
      "de ADP\n",
      "cuyo PRON\n",
      "nombre NOUN\n",
      "no ADV\n",
      "quiero VERB\n",
      "acordarme PROPN\n",
      ", PUNCT\n",
      "\n",
      " SPACE\n",
      "vivió VERB\n",
      "no ADV\n",
      "hace VERB\n",
      "mucho DET\n",
      "tiempo NOUN\n",
      "un DET\n",
      "hidalgo NOUN\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n",
      "Nuestro DET\n",
      "hidalgo NOUN\n",
      "se PRON\n",
      "llamaba VERB\n",
      "Alonso PROPN\n",
      "Quijano PROPN\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n",
      "Tenía VERB\n",
      "muchos DET\n",
      "años NOUN\n",
      "y CCONJ\n",
      "era AUX\n",
      "muy ADV\n",
      "delgado ADJ\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n",
      "Don PROPN\n",
      "Alonso PROPN\n",
      "poseía VERB\n",
      "un DET\n",
      "caballo NOUN\n",
      "flaco ADJ\n",
      ", PUNCT\n",
      "\n",
      " SPACE\n",
      "unas DET\n",
      "tierras NOUN\n",
      "y CCONJ\n",
      "una DET\n",
      "casa NOUN\n",
      "muy ADV\n",
      "grande ADJ\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n",
      "El DET\n",
      "hidalgo NOUN\n",
      "vivía VERB\n",
      "con ADP\n",
      "su DET\n",
      "joven NOUN\n",
      "sobrina NOUN\n",
      "\n",
      " SPACE\n",
      "y CCONJ\n",
      "una DET\n",
      "criada NOUN\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n"
     ]
    }
   ],
   "source": [
    "# Indica qué tipo de palabra es cada elemento de texto\n",
    "for i in documento:\n",
    "    print(i,i.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proper noun\n",
      "noun\n",
      "punctuation\n",
      "numeral\n",
      "adjective\n",
      "verb\n"
     ]
    }
   ],
   "source": [
    "# Si no sabemos que significa algo podemos usar el método 'spacy.explain'\n",
    "\n",
    "print(spacy.explain('PROPN'))\n",
    "print(spacy.explain('NOUN'))\n",
    "print(spacy.explain('PUNCT'))\n",
    "print(spacy.explain('NUM'))\n",
    "print(spacy.explain('ADJ'))\n",
    "print(spacy.explain('VERB'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "-\n",
      "En un pueblo de la Mancha,\n",
      "de cuyo nombre no quiero acordarme,\n",
      "vivió no hace mucho tiempo un hidalgo.\n",
      "\n",
      "-\n",
      "Nuestro hidalgo se llamaba Alonso Quijano.\n",
      "\n",
      "-\n",
      "Tenía muchos años y era muy delgado.\n",
      "\n",
      "-\n",
      "Don Alonso poseía un caballo flaco,\n",
      "unas tierras y una casa muy grande.\n",
      "\n",
      "-\n",
      "El hidalgo vivía con su joven sobrina\n",
      "y una criada. \n",
      "\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# Separa las oraciones del texto.\n",
    "for oracion in documento.sents:\n",
    "    print(oracion)\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm') #es_core_news_sm este modelo hay que instalarlo para trabajar en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un pasaje de avión, sin escalas, desde Uruguay hacia EE.UU. cuesta $471,88.\n"
     ]
    }
   ],
   "source": [
    "texto = 'Un pasaje de avión, sin escalas, desde Uruguay hacia EE.UU. cuesta $471,88.'\n",
    "documento = nlp(texto)\n",
    "print(documento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un\n",
      "pasaje\n",
      "de\n",
      "avión\n",
      ",\n",
      "sin\n",
      "escalas\n",
      ",\n",
      "desde\n",
      "Uruguay\n",
      "hacia\n",
      "EE.UU.\n",
      "cuesta\n",
      "$\n",
      "471,88\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in documento:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "print(type(i)) #son objetos token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Probamos diferentes métodos:\n",
    "\n",
    "for i in documento:\n",
    "    print(i.is_currency) # Te dice si i es una moneda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un\n",
      "pasaje\n",
      "de\n",
      "avión\n",
      ",\n",
      "sin\n",
      "escalas\n",
      ",\n",
      "desde\n",
      "uruguay\n",
      "hacia\n",
      "ee.uu.\n",
      "cuesta\n",
      "$\n",
      "471,88\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in documento:\n",
    "    print(i.lower_) # Si hay una letra en mayúscula, la pone en minúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in documento:\n",
    "    print(i.is_punct) # Te dice si i es un signo de puntuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un\n",
      "de\n",
      "sin\n",
      "desde\n",
      "hacia\n"
     ]
    }
   ],
   "source": [
    "for i in documento:\n",
    "    if i.is_stop: # Te muentra solo las palabras que son conectores\n",
    "        print(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pasaje\n",
      "avión\n",
      ",\n",
      "escalas\n",
      ",\n",
      "Uruguay\n",
      "EE.UU.\n",
      "cuesta\n",
      "$\n",
      "471,88\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in documento:\n",
    "    if i.is_stop == False: # Te muentra las palabras que NO son conectores\n",
    "        print(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Un pasaje de avión, sin escalas"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documento[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Uruguay"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documento[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documento[9] = 'URUGUAY'\n",
    "\n",
    "# Esto daría error porque esta clase de objeto no permite asignar valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "nlp = spacy.load('es_core_news_sm') #es_core_news_sm este modelo hay que instalarlo para trabajar en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"\"\" Los estudiosos aman estudiar, es por eso que son felices estudiando.\n",
    "su estudio es su felicidad.\n",
    "Por eso estudian felizmente sus estudios.\"\"\"\n",
    "documento= nlp(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estudiosos\n",
      "estudioso\n",
      "-\n",
      "aman\n",
      "amar\n",
      "-\n",
      "estudiar\n",
      "estudiar\n",
      "-\n",
      "felices\n",
      "feliz\n",
      "-\n",
      "estudiando\n",
      "estudiar\n",
      "-\n",
      "estudio\n",
      "estudio\n",
      "-\n",
      "felicidad\n",
      "felicidad\n",
      "-\n",
      "estudian\n",
      "estudiar\n",
      "-\n",
      "felizmente\n",
      "felizmente\n",
      "-\n",
      "estudios\n",
      "estudio\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# Revisa los signos de puntuación, si es un conecto o espacio y si uno de estos es verdadero pasamos al siguiente. Y si no, nos lo muestra por panatlla con su lema\n",
    "\n",
    "for i in documento:\n",
    "    if i.is_punct or i.is_stop or i.is_space:\n",
    "        continue\n",
    "    print(i)\n",
    "    print(i.lemma_)\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "quijote = '''\n",
    "Don Alonso necesitaba\n",
    "también un buen caballo.\n",
    "Un caballo joven y fuerte.\n",
    "Don Alonso se acercó a la cuadra.\n",
    "Allí estaba su caballo.\n",
    "Aunque era flaco y enfermizo,\n",
    "a don Alonso le pareció el mejor caballo.\n",
    "Quiso ponerle un nombre sonoro.\n",
    "Tardó 4 días en encontrar\n",
    "un nombre para el animal. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_quijote = nlp(quijote)\n",
    "\n",
    "lista_tokens_lemmas = []\n",
    "\n",
    "for i in doc_quijote:\n",
    "    if i.is_punct or i.is_stop or i.is_space:\n",
    "        continue\n",
    "    lista_tokens_lemmas.append([i.lower_,i.lemma_.lower()]) #Si no es puntuación, conector y espacio lo añade a la lista en minúscula y con su lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>don</td>\n",
       "      <td>don</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alonso</td>\n",
       "      <td>alonso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>necesitaba</td>\n",
       "      <td>necesitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>caballo</td>\n",
       "      <td>caballo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>caballo</td>\n",
       "      <td>caballo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>joven</td>\n",
       "      <td>joven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fuerte</td>\n",
       "      <td>fuerte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>don</td>\n",
       "      <td>don</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>alonso</td>\n",
       "      <td>alonso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>acercó</td>\n",
       "      <td>acercar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Token      Lemma\n",
       "0         don        don\n",
       "1      alonso     alonso\n",
       "2  necesitaba  necesitar\n",
       "3     caballo    caballo\n",
       "4     caballo    caballo\n",
       "5       joven      joven\n",
       "6      fuerte     fuerte\n",
       "7         don        don\n",
       "8      alonso     alonso\n",
       "9      acercó    acercar"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_lemmas_df = pd.DataFrame(lista_tokens_lemmas, columns=['Token','Lemma'])\n",
    "tokens_lemmas_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Token\n",
       "caballo    4\n",
       "alonso     3\n",
       "don        3\n",
       "nombre     2\n",
       "4          1\n",
       "joven      1\n",
       "sonoro     1\n",
       "quiso      1\n",
       "ponerle    1\n",
       "pareció    1\n",
       "Name: Token, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Las palabras que más se repiten en el texto según el token\n",
    "\n",
    "agrupado = tokens_lemmas_df.groupby('Token')['Token'].count()\n",
    "agrupado.sort_values(ascending=False,inplace=True)\n",
    "agrupado.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma\n",
       "caballo     4\n",
       "alonso      3\n",
       "don         3\n",
       "nombre      2\n",
       "4           1\n",
       "joven       1\n",
       "sonoro      1\n",
       "querer      1\n",
       "poner él    1\n",
       "parecer     1\n",
       "Name: Lemma, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Las palabras que más se repiten en el texto según el lemma\n",
    "\n",
    "agrupado = tokens_lemmas_df.groupby('Lemma')['Lemma'].count()\n",
    "agrupado.sort_values(ascending=False,inplace=True)\n",
    "agrupado.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Reconocimiento de entidades (NER)\n",
    "\n",
    "Usamos este modelo: es_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('es_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'Steve Jobs fue uno de los cofundadores de la empresa Apple'\n",
    "documento = nlp(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(documento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steve Jobs PER\n",
      "Apple ORG\n"
     ]
    }
   ],
   "source": [
    "# Localiza que elemen\n",
    "for i in documento.ents:\n",
    "    print(i.text, i.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named person or family.\n",
      "Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "print(spacy.explain('PER'))\n",
    "print(spacy.explain('ORG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(documento.ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "print(type(documento.ents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "María PER\n",
      "Nutella MISC\n"
     ]
    }
   ],
   "source": [
    "texto = 'María está deseando merendar una tostada con crema de chocolate de la marca Nutella'\n",
    "documento = nlp(texto)\n",
    "for i in documento.ents:\n",
    "    print(i.text, i.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miscellaneous entities, e.g. events, nationalities, products or works of art\n"
     ]
    }
   ],
   "source": [
    "print(spacy.explain('MISC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sevilla LOC\n"
     ]
    }
   ],
   "source": [
    "texto = 'Sevilla es una ciudad muy bonita, pero no es ideal visitarla en verano'\n",
    "documento = nlp(texto)\n",
    "for i in documento.ents:\n",
    "    print(i.text, i.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-GPE locations, mountain ranges, bodies of water\n"
     ]
    }
   ],
   "source": [
    "print(spacy.explain('LOC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = '''1- Usain Bolt - 100m lisos (Londres 2012)\n",
    "El corredor jamaicano voló en los Juegos Olímpicos de Londres con un 9,63 en la prueba de los 100 lisos que estuvo cerca de superar incluso su récord del mundo. Es una de sus actuaciones más memorables y de las más desafiantes para los próximos tiempos.\n",
    "\n",
    "2- Florence Griffith Joyner - 200m lisos (Seúl 1988)\n",
    "Este récord, además de Olímpico, es mundial. La velocista norteamericana voló en los Juegos Olímpicos de Seúl para dejar un 21,34 apoteósico, que se mantiene 32 años más tarde como mejor marca olímpica de la distancia.\n",
    "\n",
    "3- David Rudisha - 800m lisos (Londres 2012)\n",
    "El atleta keniata literalmente 'voló' en el 800 de Londres rebajando en un segundo la anterior marca de la distancia. Una portentosa exhibición que le dejó en bandeja la medalla de oro y que a día de hoy, su 1:40,91, que también es el récord del mundo parezca insuperable.\n",
    "\n",
    "4- Nadia Comaneci - Gimnasia (Montreal 1976)\n",
    "Su '10' en las Olimpiadas del 76 (fueron varios) se convertía en las primeras veces que alguien lograba un ejercicio perfecto en la disciplina. Obviamente la marca es insuperable pero la actuación de la gimnasta rumana fue todo una revolución en el mundo de la gimnasia.\n",
    "\n",
    "5- Kenenisa Bekele - 10.000m lisos (Pekín 2008)\n",
    "Una de las actuaciones más portentosas de uno de los mejores atletas de todos los tiempos. El etíope dejó un sensacional 27:01,17 en Pekín y de momento, nadie ha corrido más rápido en unos juegos. Histórico.\n",
    "\n",
    "6 - Michael Phelps - 200m mariposa (Pekín 2008)\n",
    "Ponemos 200m mariposa pero el nadador con más medallas de la historia de los juegos se llevo el récord olímpico en el 200 libre, 200 mariposa, 200 estilos, 400 estilos, 4x100 y 4 x 200. Una auténtica locura solo al alcance de don Michael Phelps.\n",
    "\n",
    "7 - Yelena Isinbáyeva - Salto con pértiga (Pekín 2008)\n",
    "5,05 saltó Isinbáyeva en China en la mejor actuación olímpica de su carrera. La saltadora rusa dejó la marca en esa edición de los Juegos como guinda a una trayectoria tiránica en la que dominó a placer la disciplina.\n",
    "\n",
    "8 - Jamaica - 4x100m lisos (Londres 2012)\n",
    "Un equipo de ensueño que pulverizó el récord olímpico y el mundial (36,84 s). Carter, Frater, Blake y el mismísimo Usain Bolt fueron los encargados de llevar a cabo la hazaña y marcar un tiempo que durará años como intocable.\n",
    "\n",
    "9 - Bob Beamon - Salto de Longitud (México 1968)\n",
    "Es el récord olímpico más antiguo del atletismo en la actualidad. Nadie ha saltado más que el americano desde México (8,90) y da miedo pensar qué podría haber hecho este hombre con los métodos de entrenamiento y mejoras de rendimiento que se utilizan en la actualidad. ¡Han pasado casi 60 años!\n",
    "\n",
    "10 - Estados Unidos - Baloncesto (Londres 2012)\n",
    "Cambiando un poco el tercio, volvemos a Londres en lo que fue una noche mágica para la historia del baloncesto olímpico. El 'Team USA' le endosó 156 puntos a Nigeria marcando la anotación más alta vista en cualquier partido de estos torneos. 37 puntos de un estelar Carmelo Anthony (¡Con 10 triples!) rubricaron la gran victoria estadounidense.'''\n",
    "documento = nlp(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(documento))\n",
    "print(len(documento.ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usain Bolt\n",
      "Florence Griffith Joyner\n",
      "David Rudisha\n",
      "Nadia Comaneci\n",
      "Kenenisa Bekele\n",
      "Michael Phelps\n",
      "Michael Phelps\n",
      "Yelena Isinbáyeva\n",
      "Carter\n",
      "Frater\n",
      "Blake\n",
      "Usain Bolt\n",
      "Bob Beamon\n",
      "Carmelo Anthony\n"
     ]
    }
   ],
   "source": [
    "for i in documento.ents:\n",
    "    if i.label_ == 'PER':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('text.txt', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "document = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217\n"
     ]
    }
   ],
   "source": [
    "print(len(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(document.ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in document.ents:\n",
    "    if i.label_ == 'ORG':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay ninguna organización en el texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Patrones (Matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = '''\n",
    "La Copa Mundial de Fútbol es un evento deportivo que se celebra cada 4 años. Se celebró por primera vez en Uruguay en el año 1930. En la última edición participaron 32 equipos.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "documento = nlp(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab) # Pasar todo el vocabulario del modelo es_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "patron_1 = [{'LEMMA':'celebrar'}] # definimos el patrón que busque todos los tokens que tengan como lemma 'celebrar'. Lo hacemos definiendo un diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('celebrar',[patron_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = matcher(documento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(resultados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4170701316898965175, 12, 13)\n",
      "(4170701316898965175, 18, 19)\n"
     ]
    }
   ],
   "source": [
    "for i in resultados:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genera 2 tuplas con 3 elementos:\n",
    "- Primer elemento: codigo hash\n",
    "- Segundo elemento: donde comienza ese resultado\n",
    "- Tercer elemento: donde finaliza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< Nuevo match >>>\n",
      "--- Lemma\n",
      "celebrar\n",
      "--- Palabra encontrada\n",
      "celebra\n",
      "<<< Nuevo match >>>\n",
      "--- Lemma\n",
      "celebrar\n",
      "--- Palabra encontrada\n",
      "celebró\n"
     ]
    }
   ],
   "source": [
    "for codigo_hash, comienzo, fin in resultados:\n",
    "    print( '<<< Nuevo match >>>')\n",
    "    print('--- Lemma')\n",
    "    print(nlp.vocab.strings[codigo_hash])\n",
    "    print('--- Palabra encontrada')\n",
    "    print(documento[comienzo:fin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.span.Span'>\n",
      "celebra\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "celebró\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('celebrar', [patron_1])\n",
    "resultados = matcher(documento, as_spans=True)\n",
    "\n",
    "for i in resultados:\n",
    "    print(type(i))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celebra\n",
      "4\n",
      "celebró\n",
      "1930\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "patron_2 = [{'IS_DIGIT':True}]\n",
    "matcher.add('num',[patron_2])\n",
    "resultados = matcher(documento, as_spans=True)\n",
    "for i in resultados:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1930\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "matcher.remove('celebrar')\n",
    "resultados = matcher(documento, as_spans=True)\n",
    "for i in resultados:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"\"\"\n",
    "El índice Standard & Poor's 500 (Standard & Poor's 500 Index), también conocido como S&P 500, es uno de los índices bursátiles más importantes de Estados Unidos. Al S&P 500 se le considera el índice más representativo de la situación real del mercado.3​\n",
    "\n",
    "El índice se basa en la capitalización bursátil de 500 grandes empresas que poseen acciones que cotizan en las bolsas NYSE o NASDAQ, y captura aproximadamente el 80% de toda la capitalización de mercado en Estados Unidos. Los componentes del índice S&P 500 y su ponderación son determinados por S&P Dow Jones Indices. Se diferencia de otros índices de mercados financieros de Estados Unidos, tales como el Dow Jones Industrial Average o el índice Nasdaq Composite, en la diversidad de los rubros que lo conforman y en su metodología de ponderación. Es uno de los índices de valores más seguidos, y muchas personas lo consideran el más representativo del mercado de acciones de Estados Unidos, y el marcador de tendencias de la economía norteamericana.3​ El National Bureau of Economic Research ha clasificado a las acciones comunes como un indicador relevante de los ciclos de negocios.4​\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "documento = nlp(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El índice Standard & Poor's 500 (Standard & Poor's 500 Index), también conocido como S&P 500, es uno de los índices bursátiles más importantes de Estados Unidos.\n",
      "Al S&P 500 se le considera el índice más representativo de la situación real del mercado.3​\n",
      "\n",
      "El índice se basa en la capitalización bursátil de 500 grandes empresas que poseen acciones que cotizan en las bolsas NYSE o NASDAQ, y captura aproximadamente el 80% de toda la capitalización de mercado en Estados Unidos.\n",
      "Los componentes del índice S&P 500 y su ponderación son determinados por S&P Dow Jones Indices.\n",
      "Se diferencia de otros índices de mercados financieros de Estados Unidos, tales como el Dow Jones Industrial Average o el índice Nasdaq Composite, en la diversidad de los rubros que lo conforman y en su metodología de ponderación.\n",
      "Es uno de los índices de valores más seguidos, y muchas personas lo consideran el más representativo del mercado de acciones de Estados Unidos, y el marcador de tendencias de la economía norteamericana.3​ El National Bureau of Economic Research ha clasificado a las acciones comunes como un indicador relevante de los ciclos de negocios.4​\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in documento.sents: # recorre todas las horaciones del documento\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "índice\n",
      "índices\n",
      "índice\n",
      "índice\n",
      "índice\n",
      "índices\n",
      "índice\n",
      "índices\n"
     ]
    }
   ],
   "source": [
    "patron_0 = [{'LEMMA': 'índice'}]\n",
    "matcher_0 = Matcher(nlp.vocab)\n",
    "matcher_0.add('índice',[patron_0])\n",
    "resultados = matcher_0(documento, as_spans=True)\n",
    "\n",
    "for i in resultados:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "patron_1 = [{'LEMMA': 'índice'}, {'LENGTH':6}] #busca un elemento que tenga el lemma índice y a continuación un elemento de patrón 6 de longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "índice Nasdaq\n"
     ]
    }
   ],
   "source": [
    "matcher_1 = Matcher(nlp.vocab)\n",
    "matcher_1.add('índice',[patron_1])\n",
    "resultados = matcher_1(documento, as_spans=True)\n",
    "\n",
    "for i in resultados:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiene el elemento índice + otro elemento de 6 de longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "patron_2 = [{'LEMMA': 'índice'}, {'LENGTH': {\">=\": 5}}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "índice Standard\n",
      "índices bursátiles\n",
      "índice Nasdaq\n"
     ]
    }
   ],
   "source": [
    "matcher_2 = Matcher(nlp.vocab)\n",
    "matcher_2.add('índice',[patron_2])\n",
    "resultados = matcher_2(documento, as_spans=True)\n",
    "\n",
    "for i in resultados:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "patron_3 = [{'LEMMA': 'índice'}, {'POS':'ADJ'}]  # A continuación de índice tiene que ser un adjetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "índices bursátiles\n"
     ]
    }
   ],
   "source": [
    "matcher_3 = Matcher(nlp.vocab)\n",
    "matcher_3.add('índice',[patron_3])\n",
    "resultados = matcher_3(documento, as_spans=True)\n",
    "\n",
    "for i in resultados:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "patron_4 = [{'TEXT': {'REGEX': \"[Nn][Aa][Ss][Dd][Aa][Qq]\"}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASDAQ\n",
      "Nasdaq\n"
     ]
    }
   ],
   "source": [
    "matcher_4 = Matcher(nlp.vocab)\n",
    "matcher_4.add('índice',[patron_4])\n",
    "resultados = matcher_4(documento, as_spans=True)\n",
    "\n",
    "for i in resultados:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "patron_5 = [{'IS_PUNCT':False},\n",
    "            {'IS_DIGIT':False},\n",
    "            {'IS_DIGIT':False},\n",
    "            {'IS_DIGIT': True}\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard & Poor's 500\n",
      "Standard & Poor's 500\n",
      "conocido como S&P 500\n",
      "capitalización bursátil de 500\n",
      "del índice S&P 500\n"
     ]
    }
   ],
   "source": [
    "matcher_5 = Matcher(nlp.vocab)\n",
    "matcher_5.add('índice',[patron_5])\n",
    "resultados = matcher_5(documento, as_spans=True)\n",
    "\n",
    "for i in resultados:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
