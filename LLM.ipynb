{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de Lenguaje Grande (LLM)\n",
    "\n",
    "Los Modelos de Lenguaje Grande (LLM, por sus siglas en inglés) son modelos de inteligencia artificial diseñados para comprender y generar texto humano. Se basan en redes neuronales profundas, específicamente en arquitecturas de transformadores, y son entrenados con enormes cantidades de datos textuales.\n",
    "\n",
    "## Conceptos Clave\n",
    "\n",
    "- **Transformador**: Arquitectura de red neuronal que utiliza mecanismos de atención para procesar el texto. Permite a los modelos comprender el contexto de las palabras en una secuencia.\n",
    "- **Atención**: Mecanismo que permite al modelo enfocarse en diferentes partes del texto según sea necesario, mejorando la comprensión y generación de texto.\n",
    "- **Preentrenamiento y Ajuste Fino**: El modelo se preentrena en un gran corpus de texto para aprender patrones generales del lenguaje y luego se ajusta con datos específicos para tareas particulares.\n",
    "- **Tokenización**: Proceso de convertir el texto en tokens (piezas más pequeñas, como palabras o subpalabras) que el modelo puede procesar.\n",
    "\n",
    "## Construcción de un LLM\n",
    "\n",
    "1. **Tokenización**: Dividir el texto en tokens que el modelo pueda entender. Los tokens pueden ser palabras, subpalabras o caracteres.\n",
    "2. **Entrenamiento del Modelo**: Entrenar el modelo de transformador con un gran corpus de datos textuales para aprender las estructuras y patrones del lenguaje.\n",
    "3. **Ajuste Fino**: Refinar el modelo preentrenado con datos específicos para tareas concretas, mejorando su rendimiento en dichas tareas.\n",
    "\n",
    "### Suposiciones y Consideraciones\n",
    "\n",
    "- **Tamaño del Modelo**: Los LLM pueden tener miles de millones de parámetros, lo que permite una comprensión profunda del lenguaje pero también requiere grandes recursos computacionales.\n",
    "- **Datos de Entrenamiento**: La calidad y diversidad de los datos de entrenamiento son cruciales para el rendimiento del modelo.\n",
    "- **Capacidad de Generalización**: Aunque los LLM pueden generar texto coherente y contextual, su capacidad de generalización depende de los datos y tareas específicas para las que han sido entrenados.\n",
    "\n",
    "### Ventajas y Desventajas\n",
    "\n",
    "- **Ventajas**:\n",
    "  - Capaces de comprender y generar texto con alta coherencia y contexto.\n",
    "  - Pueden realizar una amplia variedad de tareas de procesamiento de lenguaje natural (NLP).\n",
    "  - Mejoran continuamente con el ajuste fino y el entrenamiento adicional.\n",
    "\n",
    "- **Desventajas**:\n",
    "  - Requieren enormes recursos computacionales para el entrenamiento y la inferencia.\n",
    "  - Pueden generar texto sesgado o inapropiado si los datos de entrenamiento contienen dichos sesgos.\n",
    "  - La interpretación de sus predicciones puede ser compleja.\n",
    "\n",
    "### Métricas de Evaluación para LLM\n",
    "\n",
    "| Métrica               | Qué Mide                                                 | Interpretación                                   | Cuándo Usarla                                             | Cuándo No Usarla                                           |\n",
    "|-----------------------|----------------------------------------------------------|--------------------------------------------------|-----------------------------------------------------------|------------------------------------------------------------|\n",
    "| Perplejidad           | Mide qué tan bien un modelo predice una muestra          | Valor más bajo es mejor                          | Evaluar la capacidad de predicción del modelo              | En tareas de generación de texto donde la perplejidad no sea intuitiva |\n",
    "| Exactitud (Accuracy)  | Proporción de predicciones correctas                    | Valor entre 0 y 1, donde 1 es perfecto           | Evaluar tareas de clasificación                           | Cuando las clases están desbalanceadas                     |\n",
    "| F1 Score              | Media armónica de precision y recall                    | Valor entre 0 y 1, donde 1 es perfecto           | Evaluar el equilibrio entre precision y recall            | Cuando las clases están desbalanceadas o se prefiere una métrica unidimensional |\n",
    "| AUC-ROC               | Área bajo la curva ROC (Receiver Operating Characteristic) | Valor entre 0 y 1, donde 1 es perfecto           | Evaluar la capacidad del modelo para distinguir entre clases | Cuando necesitas una métrica interpretable de manera directa y unidimensional |\n",
    "| BLEU                  | Mide la calidad de texto traducido comparándolo con una referencia | Valor más alto es mejor                          | Evaluar la calidad de la traducción automática            | Cuando se prefieren evaluaciones más cualitativas          |\n",
    "| ROUGE                 | Mide la calidad de los resúmenes comparándolos con una referencia | Valor más alto es mejor                          | Evaluar la calidad de la generación de resúmenes          | Cuando se prefieren evaluaciones más cualitativas          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cómo entender el nombre de un modelo LLM en Hugging Face\n",
    "\n",
    "- Ejem: TheBloke/LLaMa2-13B-TiefighterLR-GGUF\n",
    "* **TheBloke**: nombre de usuario\n",
    "* **LLaMa2**: es el nombre del modelo base en el que se basa este modelo específico. LLaMa (Large Language Model Meta AI) es una familia de modelos de lenguaje de gran escala desarrollados por Meta (anteriormente Facebook). Estos modelos están diseñados para tareas de procesamiento de lenguaje natural (NLP) como generación de texto, clasificación, traducción y más.\n",
    "* **13B**: indica el tamaño del modelo, específicamente que tiene 13 mil millones (billion) de parámetros. Los parámetros son las variables internas que el modelo ajusta durante el entrenamiento. Un mayor número de parámetros generalmente permite que el modelo capture patrones más complejos y genere respuestas más precisas.\n",
    "* **TiefighterLR**: se refiere a optimizaciones específicas aplicadas al modelo. Aunque el nombre en sí no proporciona todos los detalles, típicamente, estas etiquetas indican técnicas o configuraciones específicas usadas durante el entrenamiento del modelo para mejorar su rendimiento. \"LR\" podría referirse a \"Learning Rate\" (tasa de aprendizaje), un parámetro importante en el entrenamiento de modelos de machine learning.\n",
    "* **GGUF**: se refiere a un formato de cuantización utilizado para el modelo. La cuantización es una técnica que reduce el tamaño del modelo y mejora la velocidad de inferencia al representar los parámetros con menos bits (por ejemplo, usar 8 bits en lugar de 32 bits). Esto permite que los modelos sean más eficientes y se puedan ejecutar en hardware con recursos limitados sin una pérdida significativa en la precisión.formato de comprensión. Pueden ser:\n",
    "  - **GPTQ**\n",
    "  - **AWG**\n",
    "  - **GGML (antiguo)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
